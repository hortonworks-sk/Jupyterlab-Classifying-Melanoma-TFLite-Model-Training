{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b4ed8419-7ade-4934-ba83-68cb0865e6be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "image_path = \"./data\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e51564ce-1b6f-499e-8f3d-3b6963978a58",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "assert tf.__version__.startswith('2')\n",
    "\n",
    "from tflite_model_maker import model_spec\n",
    "from tflite_model_maker import image_classifier\n",
    "from tflite_model_maker.config import ExportFormat\n",
    "from tflite_model_maker.config import QuantizationConfig\n",
    "from tflite_model_maker.image_classifier import DataLoader\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06702f4f-e4d4-45e6-ba46-c42ca8cf0d4b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 00:10:21.222967: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:24.995952: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:24.998790: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Load image with size: 1360, num_label: 2, labels: benign, malignant.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 00:10:25.002255: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-04-11 00:10:25.002649: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:25.004647: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:25.006570: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:25.882803: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:25.883817: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:25.884595: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:936] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2023-04-11 00:10:25.885311: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13657 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:1e.0, compute capability: 7.5\n"
     ]
    }
   ],
   "source": [
    "data = DataLoader.from_folder(image_path)\n",
    "train_data, test_data = data.split(0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "508aa018-9e52-4d64-a683-416e1f0e3a7d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Retraining the models...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " hub_keras_layer_v1v2_2 (Hub  (None, 1280)             3413024   \n",
      " KerasLayerV1V2)                                                 \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 1280)              0         \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 2)                 2562      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,415,586\n",
      "Trainable params: 2,562\n",
      "Non-trainable params: 3,413,024\n",
      "_________________________________________________________________\n",
      "None\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-11 19:07:35.549027: W tensorflow/core/framework/op_kernel.cc:1745] OP_REQUIRES failed at whole_file_read_ops.cc:116 : NOT_FOUND: /home/ec2-user/SageMaker/data/malignant/.ipynb_checkpoints; No such file or directory\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/38 [..............................] - ETA: 2:13 - loss: 0.7819 - accuracy: 0.4688"
     ]
    },
    {
     "ename": "NotFoundError",
     "evalue": "Graph execution error:\n\n2 root error(s) found.\n  (0) NOT_FOUND:  /home/ec2-user/SageMaker/data/malignant/.ipynb_checkpoints; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_33209]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotFoundError\u001b[0m                             Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_302/147908746.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mimage_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(cls, train_data, model_spec, validation_data, batch_size, epochs, steps_per_epoch, train_whole_model, dropout_rate, learning_rate, momentum, shuffle, use_augmentation, use_hub_library, warmup_steps, model_dir, do_train)\u001b[0m\n\u001b[1;32m    337\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdo_train\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    338\u001b[0m       \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mv1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlogging\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Retraining the models...'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m       \u001b[0mimage_classifier\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    341\u001b[0m       \u001b[0;31m# Used in evaluation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/image_classifier.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_data, validation_data, hparams, steps_per_epoch)\u001b[0m\n\u001b[1;32m    189\u001b[0m       \u001b[0mtrain_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_image_classifier_lib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhub_train_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    190\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 191\u001b[0;31m     self.history = train_model(\n\u001b[0m\u001b[1;32m    192\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0mhparams\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/tensorflow_examples/lite/model_maker/core/task/train_image_classifier_lib.py\u001b[0m in \u001b[0;36mhub_train_model\u001b[0;34m(model, hparams, train_ds, validation_ds, steps_per_epoch)\u001b[0m\n\u001b[1;32m    138\u001b[0m       metrics=[\"accuracy\"])\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m   return model.fit(\n\u001b[0m\u001b[1;32m    141\u001b[0m       \u001b[0mtrain_ds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m       \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mhparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_epochs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 54\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     55\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNotFoundError\u001b[0m: Graph execution error:\n\n2 root error(s) found.\n  (0) NOT_FOUND:  /home/ec2-user/SageMaker/data/malignant/.ipynb_checkpoints; No such file or directory\n\t [[{{node ReadFile}}]]\n\t [[IteratorGetNext]]\n  (1) CANCELLED:  Function was cancelled before it was started\n0 successful operations.\n0 derived errors ignored. [Op:__inference_train_function_33209]"
     ]
    }
   ],
   "source": [
    "model = image_classifier.create(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d8e33507-36ee-4650-ac53-2da1b00361a0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tdqm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_302/312555460.py\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mstruct\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0munpack\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtdqm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tdqm'"
     ]
    }
   ],
   "source": [
    "from struct import unpack\n",
    "import os\n",
    "import tdqm\n",
    "\n",
    "\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "    \n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]            \n",
    "            if len(data)==0:\n",
    "                break        \n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "for img in tqdm(images):\n",
    "  image = osp.join(root_img,img)\n",
    "  image = JPEG(image) \n",
    "  try:\n",
    "    image.decode()   \n",
    "  except:\n",
    "    bads.append(img)\n",
    "\n",
    "\n",
    "for name in bads:\n",
    "  os.remove(osp.join(root_img,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfed2eb-ef52-481e-a1c1-58c248f5e046",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "import os\n",
    "import tdqm\n",
    "\n",
    "\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "    \n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]            \n",
    "            if len(data)==0:\n",
    "                break        \n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "for img in tqdm(images):\n",
    "  image = osp.join(root_img,img)\n",
    "  image = JPEG(image) \n",
    "  try:\n",
    "    image.decode()   \n",
    "  except:\n",
    "    bads.append(img)\n",
    "\n",
    "\n",
    "for name in bads:\n",
    "  os.remove(osp.join(root_img,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de96ce32-f377-4e4e-9fde-0fc9337cd59b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pip install tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cdc6d7-3dea-4111-9a45-1de60316cde7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from struct import unpack\n",
    "import os\n",
    "import tdqm\n",
    "\n",
    "\n",
    "marker_mapping = {\n",
    "    0xffd8: \"Start of Image\",\n",
    "    0xffe0: \"Application Default Header\",\n",
    "    0xffdb: \"Quantization Table\",\n",
    "    0xffc0: \"Start of Frame\",\n",
    "    0xffc4: \"Define Huffman Table\",\n",
    "    0xffda: \"Start of Scan\",\n",
    "    0xffd9: \"End of Image\"\n",
    "}\n",
    "\n",
    "\n",
    "class JPEG:\n",
    "    def __init__(self, image_file):\n",
    "        with open(image_file, 'rb') as f:\n",
    "            self.img_data = f.read()\n",
    "    \n",
    "    def decode(self):\n",
    "        data = self.img_data\n",
    "        while(True):\n",
    "            marker, = unpack(\">H\", data[0:2])\n",
    "            # print(marker_mapping.get(marker))\n",
    "            if marker == 0xffd8:\n",
    "                data = data[2:]\n",
    "            elif marker == 0xffd9:\n",
    "                return\n",
    "            elif marker == 0xffda:\n",
    "                data = data[-2:]\n",
    "            else:\n",
    "                lenchunk, = unpack(\">H\", data[2:4])\n",
    "                data = data[2+lenchunk:]            \n",
    "            if len(data)==0:\n",
    "                break        \n",
    "\n",
    "\n",
    "bads = []\n",
    "\n",
    "for img in tqdm(images):\n",
    "  image = osp.join(root_img,img)\n",
    "  image = JPEG(image) \n",
    "  try:\n",
    "    image.decode()   \n",
    "  except:\n",
    "    bads.append(img)\n",
    "\n",
    "\n",
    "for name in bads:\n",
    "  os.remove(osp.join(root_img,name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6eafa3a7-9443-4c47-a738-0cb57fe41666",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Requirement already satisfied: tdqm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (0.0.1)\n",
      "Requirement already satisfied: tqdm in /home/ec2-user/anaconda3/envs/pytorch_p39/lib/python3.9/site-packages (from tdqm) (4.63.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14d4dc8c-bcfc-4b33-ab94-3e0de6b2552c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'tdqm'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_28209/238335907.py\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtdqm\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtdqm\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tdqm'"
     ]
    }
   ],
   "source": [
    "import tdqm as tdqm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed899d4-8688-4295-ae5f-0a05e6ed1aaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting package metadata (current_repodata.json): done\n",
      "Solving environment: / \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::bleach==5.0.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytest==7.2.0=pyhd8ed1ab_2\n",
      "  - conda-forge/noarch::python-lsp-jsonrpc==1.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtpy==2.3.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::sip==6.7.5=py39h5a03fae_0\n",
      "  - conda-forge/noarch::terminado==0.17.1=pyh41d4057_0\n",
      "  - conda-forge/linux-64::watchdog==2.2.1=py39hf3d152e_0\n",
      "  - conda-forge/noarch::dask-core==2022.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask==2.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_metadata==6.0.0=hd8ed1ab_0\n",
      "  - conda-forge/noarch::nltk==3.8.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt5-sip==12.11.0=py39h5a03fae_2\n",
      "  - conda-forge/noarch::python-lsp-server-base==1.7.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytoolconfig==1.2.4=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::qdarkstyle==3.0.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtawesome==1.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask-cors==3.0.10=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::rope==1.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::keyring==23.13.1=py39hf3d152e_0\n",
      "  - conda-forge/noarch::nbformat==5.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-lsp-server==1.7.0=hd8ed1ab_0\n",
      "  - conda-forge/noarch::distributed==2022.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipykernel==6.20.1=pyh210e3f2_0\n",
      "  - conda-forge/noarch::nbclient==0.7.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt==5.15.7=py39h18e9c17_2\n",
      "  - conda-forge/noarch::python-lsp-black==1.2.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.28.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::cookiecutter==2.1.1=pyh6c4a22f_0\n",
      "  - conda-forge/noarch::jupyter_console==6.4.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-core==7.2.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pooch==1.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqtwebengine==5.15.7=py39h18e9c17_2\n",
      "  - conda-forge/noarch::qtconsole-base==5.4.0=pyha770c72_0\n",
      "  - conda-forge/linux-64::requests-kerberos==0.12.0=py39hf3d152e_4\n",
      "  - conda-forge/noarch::spyder-kernels==2.4.1=unix_pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==7.2.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::numpydoc==1.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtconsole==5.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.4=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::astropy==5.2=py39h389d5f1_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.18.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert==7.2.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook-shim==0.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pytables==3.7.0=py39h6a7961f_3\n",
      "  - conda-forge/noarch::dask==2022.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclassic==0.4.8=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::scikit-image==0.19.3=py39h4661b88_2\n",
      "  - conda-forge/linux-64::spyder==5.4.1=py39hf3d152e_1\n",
      "  - conda-forge/linux-64::statsmodels==0.13.5=py39h2ae25f5_2\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py39hf3d152e_8\n",
      "  - conda-forge/noarch::hdijupyterutils==0.20.3=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::autovizwidget==0.20.3=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::sparkmagic==0.20.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::fastcore==1.5.26=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::bokeh==2.4.3=pyhd8ed1ab_3\n",
      "  - conda-forge/linux-64::matplotlib-base==3.5.3=py39h19d6b11_2\n",
      "  - intel/linux-64::mkl_umath==0.1.1=py39h0348192_26\n",
      "  - conda-forge/linux-64::matplotlib==3.5.3=py39hf3d152e_2\n",
      "  - conda-forge/noarch::seaborn-base==0.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinx==5.1.1=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::spacy==3.4.4=py39h0354152_0\n",
      "  - pytorch/noarch::captum==0.5.0=0\n",
      "  - conda-forge/noarch::seaborn==0.11.2=hd8ed1ab_0\n",
      "  - pytorch/linux-64::torchtext==0.14.1=py39\n",
      "  - pytorch/linux-64::torchvision==0.14.1=py39_cu117\n",
      "  - fastai/noarch::fastai==2.1.10=py_0\n",
      "  - conda-forge/noarch::notebook==6.4.12=pyha770c72_0\n",
      "  - conda-forge/noarch::jupyterlab==3.3.4=pyhd8ed1ab_0\n",
      "failed with initial frozen solve. Retrying with flexible solve.\n",
      "Solving environment: failed with repodata from current_repodata.json, will retry with next repodata source.\n",
      "Collecting package metadata (repodata.json): done\n",
      "Solving environment: - \n",
      "The environment is inconsistent, please check the package plan carefully\n",
      "The following packages are causing the inconsistency:\n",
      "\n",
      "  - conda-forge/noarch::bleach==5.0.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytest==7.2.0=pyhd8ed1ab_2\n",
      "  - conda-forge/noarch::python-lsp-jsonrpc==1.0.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtpy==2.3.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::sip==6.7.5=py39h5a03fae_0\n",
      "  - conda-forge/noarch::terminado==0.17.1=pyh41d4057_0\n",
      "  - conda-forge/linux-64::watchdog==2.2.1=py39hf3d152e_0\n",
      "  - conda-forge/noarch::dask-core==2022.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask==2.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::importlib_metadata==6.0.0=hd8ed1ab_0\n",
      "  - conda-forge/noarch::nltk==3.8.1=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt5-sip==12.11.0=py39h5a03fae_2\n",
      "  - conda-forge/noarch::python-lsp-server-base==1.7.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pytoolconfig==1.2.4=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::qdarkstyle==3.0.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtawesome==1.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::flask-cors==3.0.10=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::rope==1.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::keyring==23.13.1=py39hf3d152e_0\n",
      "  - conda-forge/noarch::nbformat==5.7.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::python-lsp-server==1.7.0=hd8ed1ab_0\n",
      "  - conda-forge/noarch::distributed==2022.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::ipykernel==6.20.1=pyh210e3f2_0\n",
      "  - conda-forge/noarch::nbclient==0.7.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pyls-spyder==0.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqt==5.15.7=py39h18e9c17_2\n",
      "  - conda-forge/noarch::python-lsp-black==1.2.1=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::requests==2.28.1=pyhd8ed1ab_1\n",
      "  - conda-forge/noarch::cookiecutter==2.1.1=pyh6c4a22f_0\n",
      "  - conda-forge/noarch::jupyter_console==6.4.4=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-core==7.2.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::pooch==1.6.0=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pyqtwebengine==5.15.7=py39h18e9c17_2\n",
      "  - conda-forge/noarch::qtconsole-base==5.4.0=pyha770c72_0\n",
      "  - conda-forge/linux-64::requests-kerberos==0.12.0=py39hf3d152e_4\n",
      "  - conda-forge/noarch::spyder-kernels==2.4.1=unix_pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert-pandoc==7.2.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::numpydoc==1.5.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::qtconsole==5.4.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinxcontrib-websupport==1.2.4=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::astropy==5.2=py39h389d5f1_0\n",
      "  - conda-forge/noarch::jupyterlab_server==2.18.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbconvert==7.2.7=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::notebook-shim==0.2.2=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::pytables==3.7.0=py39h6a7961f_3\n",
      "  - conda-forge/noarch::dask==2022.11.0=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::nbclassic==0.4.8=pyhd8ed1ab_0\n",
      "  - conda-forge/linux-64::scikit-image==0.19.3=py39h4661b88_2\n",
      "  - conda-forge/linux-64::spyder==5.4.1=py39hf3d152e_1\n",
      "  - conda-forge/linux-64::statsmodels==0.13.5=py39h2ae25f5_2\n",
      "  - conda-forge/linux-64::jupyter==1.0.0=py39hf3d152e_8\n",
      "  - conda-forge/noarch::hdijupyterutils==0.20.3=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::autovizwidget==0.20.3=pyh1a96a4e_0\n",
      "  - conda-forge/noarch::sparkmagic==0.20.3=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::fastcore==1.5.26=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::bokeh==2.4.3=pyhd8ed1ab_3\n",
      "  - conda-forge/linux-64::matplotlib-base==3.5.3=py39h19d6b11_2\n",
      "  - intel/linux-64::mkl_umath==0.1.1=py39h0348192_26\n",
      "  - conda-forge/linux-64::matplotlib==3.5.3=py39hf3d152e_2\n",
      "  - conda-forge/noarch::seaborn-base==0.11.2=pyhd8ed1ab_0\n",
      "  - conda-forge/noarch::sphinx==5.1.1=pyhd8ed1ab_1\n",
      "  - conda-forge/linux-64::spacy==3.4.4=py39h0354152_0\n",
      "  - pytorch/noarch::captum==0.5.0=0\n",
      "  - conda-forge/noarch::seaborn==0.11.2=hd8ed1ab_0\n",
      "  - pytorch/linux-64::torchtext==0.14.1=py39\n",
      "  - pytorch/linux-64::torchvision==0.14.1=py39_cu117\n",
      "  - fastai/noarch::fastai==2.1.10=py_0\n",
      "  - conda-forge/noarch::notebook==6.4.12=pyha770c72_0\n",
      "  - conda-forge/noarch::jupyterlab==3.3.4=pyhd8ed1ab_0\n",
      "/ "
     ]
    }
   ],
   "source": [
    "conda install -c conda-forge tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30e40291-54b5-4ea6-abbf-2f6a104f225f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p39",
   "language": "python",
   "name": "conda_pytorch_p39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
